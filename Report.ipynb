{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156a1f90",
   "metadata": {},
   "source": [
    "# Navigation Project report\n",
    "\n",
    "A number of different agents were created to solve the 'Banana Navigation' game. A combination of These were:\n",
    "\n",
    "1. Basic Deep Queue Network using experience replay, using a linear neural network model\n",
    "2. Similar to 1, but including a 'Double' network\n",
    "3. Building on 2, but also including a 'Dueling' network\n",
    "4. Prioritised experience replay\n",
    "\n",
    "All of these implementations 'solved' the solution in so much as they achieved an average score over 100 episodes > 13. Results of these are shown below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a152d",
   "metadata": {},
   "source": [
    "## Architected for experimenting\n",
    "\n",
    "The code implemented can be broadly broken down into three main areas:\n",
    "- Agents classes\n",
    "- NN models classes\n",
    "- Experience Replay buffers classes\n",
    "\n",
    "The goal is that these three elements can be mixed and matched in order to make it easy to experiment with different configurations.\n",
    "\n",
    "So for example a different neural network model could be implemented and easily tested with both a normal experience replay buffer or a prioritised replay buffer and both of these configurations could utilise Double Q-Learning or not.\n",
    "\n",
    "### Agents\n",
    "A base agent class (BaseAgent) was implemented to support some common methods and attributes. Two sub classes were created, one to support basic replay buffers and the other to support priority experience type replay buffers. Currently the type of replay buffer is hard-coded to the specific agent, but this could be parameterised.\n",
    "\n",
    "### NN Models\n",
    "Any model can be used in conjunction with any of the agents implemented. Three models have been implemented:\n",
    "- Basic linear model with three layers. The number of units for the two hidden layers can be provided as parameters\n",
    "- Dueling linear model\n",
    "- Conv2d model, specifically for the image based state\n",
    "\n",
    "### Experience Replay buffers\n",
    "Two replay buffers have been implemented:\n",
    "- ReplayBuffer: simply stores experiences and samples randomly\n",
    "- PrioritizedReplayBuffer: this uses a sumtree to manage the prioritized experiences.\n",
    "\n",
    "#### Prioritized Replay Buffer\n",
    "The experiences themselves are stored in an array, with the adjusted priorities stored in a sumtree. \n",
    "\n",
    "When an experience is added its priority is not initially known (as this will only happen when sampled). As described in the paper [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952.pdf) all experiences should be sampled at least once, so these experiences are initially given a priority of 0 and put in a 'not prioritised' queue. When a request to provide a sample is made these unprioritised experiences will be provided before any other experiences. After an experience has been sampled its priority will be updated.\n",
    "\n",
    "Priorities are adjusted by a constant, alpha as described in the paper.\n",
    "\n",
    "Importance sampling weights are calculated when experiences are sampled and returned with the samples, so that the loss can be adjusted by these weights.\n",
    "\n",
    "Both the alpha and beta (used in calculating importance sampling weights) constants are periodically adjusted. Alpha decaying slowly and beta annealing to 1. The constants for alpha and beta have been taken from the paper.\n",
    "\n",
    "Sampling uses the priority of the experience. I divide the priority space into equal sized segments (batch size number of them) and then uniformally sample from these segments. I believe this is what the paper describes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94c71f",
   "metadata": {},
   "source": [
    "## Learning algorithms\n",
    "\n",
    "Something about the learning algorithms\n",
    "### Experience replay\n",
    "The fundamental approach adopted is described in the paper [Human-level control through deep reinforcement\n",
    "learning](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf). The implementation uses two neural networks and an experience replay buffer.\n",
    "\n",
    "### Double Q-learning\n",
    "[Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/pdf/1509.06461.pdf) attempts to tackle the known problem of action values being overestimated in certain conditions. \n",
    "For DQN using the same values both to select and to evaluate an action makes it more likely that this overestimate will occur.\n",
    "To prevent this the selection and evaluation of actions is decoupled. The selection of the action (using argmax) uses the local (online) network, whereas the evaluation uses the the target network.\n",
    "In this implementation the base agent class (AgentBase) implements this feature so that it can be utilised independently of other features that may be used.\n",
    "\n",
    "### Dueling network architectures\n",
    "A duel network architecture as described in the paper [Dueling Network Architectures for Deep Reinforcement Learning](https://arxiv.org/pdf/1511.06581.pdf) has been demonstrated to improve the performance of a reinforcment learning agent.\n",
    "This approach has been implemented as the model DuelingQNetwork\n",
    "\n",
    "### Prioritized Experience Replay\n",
    "A prioritised experience replay buffer as described in the paper [Prioritized Experience Replay](https://arxiv.org/pdf/1511.05952.pdf) has been implemented.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc644e0f",
   "metadata": {},
   "source": [
    "## Plot of rewards Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2627d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 4\n",
      "Number of agents: 1\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n",
      "Testing ddqn_with_prioritized_experiences_qnetwork\n",
      "Episode 5\tAverage Score: 16.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9f97fb3f77a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m                              \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                              \u001b[0meps_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                              checkpoint=13)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/education/udacity/rl/projects/rl_navigation/lib/dqn.py\u001b[0m in \u001b[0;36mdqn\u001b[0;34m(env, brain_name, agent, train_mode, n_episodes, max_t, eps_start, eps_end, eps_decay, checkpoint, get_state)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# send the action to the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_info\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                  \u001b[0;31m# see if episode has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")\n",
    "#env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "\n",
    "import torch\n",
    "from lib.agents import AgentExerperienceReplay, AgentPrioritizedExperience\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.dqn import dqn\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "\n",
    "\n",
    "agents = []\n",
    "\n",
    "agent = AgentExerperienceReplay(state_size=state_size, action_size=action_size, seed=0, train_mode=False)\n",
    "#agent.load_model('qnetwork')\n",
    "agents.append({'agent': agent, \n",
    "               'name': 'qnetwork', \n",
    "               'test': False,\n",
    "              })\n",
    "\n",
    "agent = AgentPrioritizedExperience(state_size=state_size, action_size=action_size, seed=0,\n",
    "                                   prioritized_experience=True,\n",
    "                                   compute_weights=True,\n",
    "                                   train_mode=False)\n",
    "\n",
    "\n",
    "agents.append({'agent': agent, 'name': 'ddqn_with_prioritized_experiences_qnetwork', 'test': True})\n",
    "\n",
    "agent = AgentPrioritizedExperience(state_size=state_size, action_size=action_size, seed=0,\n",
    "                                   prioritized_experience=True,\n",
    "                                   compute_weights=True,\n",
    "                                   train_mode=False)\n",
    "\n",
    "\n",
    "agents.append({'agent': agent, 'name': 'dueling_ddqn_with_prioritized_experiences_qnetwork', 'test': True})\n",
    "\n",
    "for info in agents:\n",
    "    if info['test']:\n",
    "        print('Testing', info['name'])\n",
    "        info['agent'].load_model(info['name'])\n",
    "        info['scores'] = dqn(env,\n",
    "                             brain_name,\n",
    "                             info['agent'], \n",
    "                             train_mode=False, \n",
    "                             n_episodes=100, \n",
    "                             eps_start=0.01,\n",
    "                             checkpoint=13)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99618590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions: 4\n",
      "Number of agents: 1\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.agents import AgentExperienceReplay, AgentPrioritizedExperienceReplay\n",
    "from lib.models import QNetwork, DuelingQNetwork\n",
    "\n",
    "\n",
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")\n",
    "#env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.dqn import dqn\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)\n",
    "\n",
    "def create_dueling_model(state_size, action_size, seed):\n",
    "    return DuelingQNetwork(state_size, action_size, seed)\n",
    "\n",
    "def create_linear_model(state_size, action_size, seed):\n",
    "    return QNetwork(state_size, action_size, seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491b18b3",
   "metadata": {},
   "source": [
    "### Dueling Network with Double Q-learning and Prioritized experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02132b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 12.85\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = 'prioritized_experiences_dueling_network_double'\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_dueling_model,\n",
    "                                         double_dqn=True,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a22c8",
   "metadata": {},
   "source": [
    "### Dueling Network with Prioritized experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fd273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 65\tAverage Score: 10.51"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = 'prioritized_experiences_dueling_network'\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_dueling_model,\n",
    "                                         double_dqn=False,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a58ec4",
   "metadata": {},
   "source": [
    "### Linear Network with Double Q-learning and Prioritized experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = 'prioritized_experiences_linear_network'\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_linear_model,\n",
    "                                         double_dqn=True,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1400789",
   "metadata": {},
   "source": [
    "### Linear Network with Prioritized experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49723b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = 'prioritized_experiences_linear_network'\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_linear_model,\n",
    "                                         double_dqn=False,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a629e165",
   "metadata": {},
   "source": [
    "### Dueling Network with Double Q-learning random experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = ''\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_dueling_model,\n",
    "                                         double_dqn=True,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ee28b",
   "metadata": {},
   "source": [
    "### Dueling Network  random experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = ''\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_dueling_model,\n",
    "                                         double_dqn=False,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a3da2",
   "metadata": {},
   "source": [
    "### Linear Network with Double Q-learning random experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = ''\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_linear_model,\n",
    "                                         double_dqn=True,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362dcceb",
   "metadata": {},
   "source": [
    "### Linear Network with random experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "agent_name = ''\n",
    "agent = AgentPrioritizedExperienceReplay(state_size=state_size, action_size=action_size, seed=0, \n",
    "                                         create_model=create_linear_model,\n",
    "                                         double_dqn=False,\n",
    "                                         train_mode=False\n",
    "                                         )\n",
    "agent.load_model(agent_name)\n",
    "\n",
    "\n",
    "scores = dqn(env,\n",
    "             brain_name,\n",
    "             agent,\n",
    "             train_mode=False,\n",
    "             n_episodes=100, \n",
    "             eps_start=0.01)\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d79003",
   "metadata": {},
   "source": [
    "## Ideas for future work\n",
    "\n",
    "### Experiment with a greater variety of network models\n",
    "A lot more experimenting with different models is needed\n",
    "\n",
    "### Using a DQN to 'learn' the best parameters\n",
    "\n",
    "It feels like there is a lot of trial and error in order to determine the best architecture (e.g. network model, double q-learning etc) and hyperparameters. Would it be possible to define a DQN that could be used to determine what were the best set of values. Parameter values could be limited to discrete values so that the state space was managable. The reward could be the average score from a number of episodes of the game.\n",
    "\n",
    "### Effective testing of subcomponents\n",
    "\n",
    "With a lot of software, bugs are very obvious. With ML code it's possible to implement features, e.g. prioritized experience replay, which appear to 'work', in so much that the agent learns, but the implementation may not perform as intended. Whilst this issue is not limited to ML code, it does seem particularly vulnerable as some components may be difficult to verify.\n",
    "\n",
    "### Image based navigation (pixel navigation)\n",
    "\n",
    "I started to explore using an image of the game as the state, although ran out of time to actually solve it. I did wonder if you used a different reward than that provided by the environment. For example what if the reward was based on how yellow or blue (perhaps using the dot product to measure the yellowness/blueness), how would this effect the performance of the agent.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
